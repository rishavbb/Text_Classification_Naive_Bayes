{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\",\"i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\Rishav\\20_newsgroups\"\n",
    "filenames=glob.glob(path+\"/*/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishav\\20_newsgroups\\alt.atheism\\51060\n"
     ]
    }
   ],
   "source": [
    "print(filenames[1])\n",
    "#the type of document is in index 4\n",
    "#so accordingly I will extract Y from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_files=filenames.copy()\n",
    "Y_files=[]\n",
    "for i in range(len(X_files)):\n",
    "    Y_files.append(filenames[i].split(\"\\\\\")[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_files,X_test_files,Y_train,Y_test=train_test_split(X_files,Y_files,random_state=0)\n",
    "#mind Y_train and Y_test and not Y_train_files and  Y_test_files because i am getting them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeUnique(data,unique):\n",
    "\n",
    "    for i in data:\n",
    "        a=i.lower() #converting into lower case as my stopwords are in lower case\n",
    "        if((a not in stopwords) and (a not in unique)):\n",
    "            \n",
    "\n",
    "            unique.append(a)  #making my unique list\n",
    "\n",
    "    return unique\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(fname):\n",
    "    '''Load the file using std open'''\n",
    "\n",
    "    f=open(fname,\"r\")  #opening the file\n",
    "    data=f.read().split()   #extracting the words and storing it in a list named \"data\"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "unique=[]\n",
    "\n",
    "for file in X_train_files:   \n",
    "\n",
    "\n",
    "    data=load(file)  #getting all the words of one document at a time in the list named data\n",
    "    unique=makeUnique(data,unique)   #finding the unique elements from it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making a copy of unique\n",
    "\n",
    "uni=unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(data, uni,frequency):\n",
    "    \n",
    "    for i in data:\n",
    "        a=i.lower()\n",
    "        if a not in stopwords:\n",
    "            w=uni.index(a)  #finding the index position of unique word\n",
    "            frequency[w]+=1  #adding the frequency of each unique word by 1 each time\n",
    "    return frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency=np.zeros(len(uni))  #to find the frequency of unique elements\n",
    "\n",
    "for file in X_train_files: \n",
    "\n",
    "    data=load(file)  #getting all the words of one document at a time in the list named data\n",
    "    frequency=count(data,uni,frequency)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18914ff2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "a=frequency.copy()  #making a copy of frequency\n",
    "\n",
    "Y_axis,X_axis=np.unique(a, return_counts=True)  #this is used to find how many unique words are there of specific frequency like number of unique words with frequencies 1 and then 2 and so on\n",
    "Y_axis=list(Y_axis)#holds the frequencies                   \n",
    "X_axis=list(X_axis)#holds the no of words with specific frequency\n",
    "plt.plot(X_axis,Y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clearly deleting the words having frequencies till 100 as they are not of so use on checking the graph\n",
    "\n",
    "\n",
    "del X_axis[:100]\n",
    "del Y_axis[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFXhJREFUeJzt3X+s3XWd5/Hny7Ygs+q2yMU0bdky\nY5MFnbVqF5q42bjoQMHJlkkkgexKY0g660JWs+6u6CbL+IOsZjMyS6IkzNChbFyBUWfouHW7DWJc\nNwq9SAVqNb2DjlzboXULCGEHBd/7x/l0OPZ72nvu7eWey73PR/L1fL/v7+fzPZ/zjdzX+f44/aaq\nkCSp36tGPQBJ0vxjOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUsXTUA5ips846\nq9auXTvqYUjSK8qDDz74s6oam6rdKzYc1q5dy/j4+KiHIUmvKEn+eph2nlaSJHUYDpKkDsNBktRh\nOEiSOgwHSVKH4SBJ6jAcJEkdiy4cbv8/P+Ivv3dw1MOQpHlt0YXDF+7/CV979NCohyFJ89qiCwdJ\n0tQMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6pgyHJK9O8kCS7yXZl+TjrX57\nkh8l2dum9a2eJDcnmUjycJK39W1rS5IDbdrSV397kkdan5uT5OX4sJKk4QzzDOnngYuq6tkky4Bv\nJflaW/fvq+pLx7W/FFjXpguBW4ALk5wJ3ABsAAp4MMmOqnqytdkKfAfYCWwCvoYkaSSmPHKonmfb\n4rI21Um6bAbuaP2+AyxPshK4BNhdVUdbIOwGNrV1r6uqb1dVAXcAl5/CZ5IknaKhrjkkWZJkL3CY\n3h/4+9uqG9upo5uSnN5qq4DH+7pPttrJ6pMD6oPGsTXJeJLxI0eODDN0SdIMDBUOVfViVa0HVgMX\nJHkz8FHgHwL/GDgT+EhrPuh6Qc2gPmgct1bVhqraMDY2NszQJUkzMK27larqKeAbwKaqOtROHT0P\n/ClwQWs2Cazp67YaODhFffWAuiRpRIa5W2ksyfI2fwbwbuAH7VoB7c6iy4FHW5cdwNXtrqWNwNNV\ndQjYBVycZEWSFcDFwK627pkkG9u2rgbumd2PKUmajmHuVloJbE+yhF6Y3F1VX03y9SRj9E4L7QX+\nVWu/E7gMmACeA94PUFVHk3wS2NPafaKqjrb5DwC3A2fQu0vJO5UkaYSmDIeqehh464D6RSdoX8C1\nJ1i3Ddg2oD4OvHmqsUiS5oa/kJYkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQ\nJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1DPMM6VcneSDJ95LsS/LxVj83\nyf1JDiS5K8lprX56W55o69f2beujrf7DJJf01Te12kSS62f/Y0qSpmOYI4fngYuq6i3AemBTko3A\nZ4Cbqmod8CRwTWt/DfBkVb0RuKm1I8n5wJXAm4BNwOeTLGnPpv4ccClwPnBVaytJGpEpw6F6nm2L\ny9pUwEXAl1p9O3B5m9/clmnr35UkrX5nVT1fVT8CJoAL2jRRVY9V1S+AO1tbSdKIDHXNoX3D3wsc\nBnYDfwU8VVUvtCaTwKo2vwp4HKCtfxp4fX/9uD4nqkuSRmSocKiqF6tqPbCa3jf98wY1a685wbrp\n1juSbE0ynmT8yJEjUw9ckjQj07pbqaqeAr4BbASWJ1naVq0GDrb5SWANQFv/94Gj/fXj+pyoPuj9\nb62qDVW1YWxsbDpDlyRNwzB3K40lWd7mzwDeDewH7gPe25ptAe5p8zvaMm3916uqWv3KdjfTucA6\n4AFgD7Cu3f10Gr2L1jtm48NJkmZm6dRNWAlsb3cVvQq4u6q+muT7wJ1JPgU8BNzW2t8G/LckE/SO\nGK4EqKp9Se4Gvg+8AFxbVS8CJLkO2AUsAbZV1b5Z+4SSpGmbMhyq6mHgrQPqj9G7/nB8/W+BK06w\nrRuBGwfUdwI7hxivJGkO+AtpSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lS\nh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqmDIckqxJcl+S/Un2Jflg\nq/9Bkp8m2dumy/r6fDTJRJIfJrmkr76p1SaSXN9XPzfJ/UkOJLkryWmz/UElScMb5sjhBeDDVXUe\nsBG4Nsn5bd1NVbW+TTsB2rorgTcBm4DPJ1mSZAnwOeBS4Hzgqr7tfKZtax3wJHDNLH0+SdIMTBkO\nVXWoqr7b5p8B9gOrTtJlM3BnVT1fVT8CJoAL2jRRVY9V1S+AO4HNSQJcBHyp9d8OXD7TDyRJOnXT\nuuaQZC3wVuD+VrouycNJtiVZ0WqrgMf7uk222onqrweeqqoXjqsPev+tScaTjB85cmQ6Q5ckTcPQ\n4ZDkNcCXgQ9V1c+BW4DfAtYDh4A/PNZ0QPeaQb1brLq1qjZU1YaxsbFhhy5JmqalwzRKsoxeMHyh\nqr4CUFVP9K3/Y+CrbXESWNPXfTVwsM0Pqv8MWJ5kaTt66G8vSRqBYe5WCnAbsL+qPttXX9nX7PeA\nR9v8DuDKJKcnORdYBzwA7AHWtTuTTqN30XpHVRVwH/De1n8LcM+pfSxJ0qkY5sjhHcD7gEeS7G21\nj9G722g9vVNAPwZ+H6Cq9iW5G/g+vTudrq2qFwGSXAfsApYA26pqX9veR4A7k3wKeIheGEmSRmTK\ncKiqbzH4usDOk/S5EbhxQH3noH5V9Ri9u5kkSfOAv5CWJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ\n6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdQzzDOk1\nSe5Lsj/JviQfbPUzk+xOcqC9rmj1JLk5yUSSh5O8rW9bW1r7A0m29NXfnuSR1ufm9txqSdKIDHPk\n8ALw4ao6D9gIXJvkfOB64N6qWgfc25YBLgXWtWkrcAv0wgS4AbiQ3iNBbzgWKK3N1r5+m079o0mS\nZmrKcKiqQ1X13Tb/DLAfWAVsBra3ZtuBy9v8ZuCO6vkOsDzJSuASYHdVHa2qJ4HdwKa27nVV9e2q\nKuCOvm1JkkZgWtcckqwF3grcD7yhqg5BL0CAs1uzVcDjfd0mW+1k9ckBdUnSiAwdDkleA3wZ+FBV\n/fxkTQfUagb1QWPYmmQ8yfiRI0emGrIkaYaGCocky+gFwxeq6iut/EQ7JUR7Pdzqk8Cavu6rgYNT\n1FcPqHdU1a1VtaGqNoyNjQ0zdEnSDAxzt1KA24D9VfXZvlU7gGN3HG0B7umrX93uWtoIPN1OO+0C\nLk6yol2IvhjY1dY9k2Rje6+r+7YlSRqBpUO0eQfwPuCRJHtb7WPAp4G7k1wD/AS4oq3bCVwGTADP\nAe8HqKqjST4J7GntPlFVR9v8B4DbgTOAr7VJkjQiU4ZDVX2LwdcFAN41oH0B155gW9uAbQPq48Cb\npxqLJGlu+AtpSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJ\nHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUscwz5DeluRwkkf7an+Q5KdJ9rbpsr51H00ykeSH\nSS7pq29qtYkk1/fVz01yf5IDSe5KctpsfkBJ0vQNc+RwO7BpQP2mqlrfpp0ASc4HrgTe1Pp8PsmS\nJEuAzwGXAucDV7W2AJ9p21oHPAlccyofSJJ06qYMh6r6JnB0yO1tBu6squer6kfABHBBmyaq6rGq\n+gVwJ7A5SYCLgC+1/tuBy6f5GSRJs+xUrjlcl+ThdtppRautAh7vazPZaieqvx54qqpeOK4uSRqh\nmYbDLcBvAeuBQ8AftnoGtK0Z1AdKsjXJeJLxI0eOTG/EkqShzSgcquqJqnqxqn4F/DG900bQ++a/\npq/pauDgSeo/A5YnWXpc/UTve2tVbaiqDWNjYzMZuiRpCDMKhyQr+xZ/Dzh2J9MO4Mokpyc5F1gH\nPADsAda1O5NOo3fRekdVFXAf8N7Wfwtwz0zGJEmaPUunapDki8A7gbOSTAI3AO9Msp7eKaAfA78P\nUFX7ktwNfB94Abi2ql5s27kO2AUsAbZV1b72Fh8B7kzyKeAh4LZZ+3SSpBmZMhyq6qoB5RP+Aa+q\nG4EbB9R3AjsH1B/jpdNSkqR5wF9IS5I6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRh\nOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSx5ThkGRbksNJHu2r\nnZlkd5ID7XVFqyfJzUkmkjyc5G19fba09geSbOmrvz3JI63PzUky2x9SkjQ9wxw53A5sOq52PXBv\nVa0D7m3LAJcC69q0FbgFemEC3ABcSO950TccC5TWZmtfv+PfS5I0x6YMh6r6JnD0uPJmYHub3w5c\n3le/o3q+AyxPshK4BNhdVUer6klgN7CprXtdVX27qgq4o29bkqQRmek1hzdU1SGA9np2q68CHu9r\nN9lqJ6tPDqhLkkZoti9ID7peUDOoD954sjXJeJLxI0eOzHCIkqSpzDQcnminhGivh1t9EljT1241\ncHCK+uoB9YGq6taq2lBVG8bGxmY4dEnSVGYaDjuAY3ccbQHu6atf3e5a2gg83U477QIuTrKiXYi+\nGNjV1j2TZGO7S+nqvm1JkkZk6VQNknwReCdwVpJJencdfRq4O8k1wE+AK1rzncBlwATwHPB+gKo6\nmuSTwJ7W7hNVdewi9wfo3RF1BvC1NkmSRmjKcKiqq06w6l0D2hZw7Qm2sw3YNqA+Drx5qnFIkuaO\nv5CWJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoM\nB0lSh+EgSeowHCRJHYaDJKnDcJAkdZxSOCT5cZJHkuxNMt5qZybZneRAe13R6klyc5KJJA8neVvf\ndra09geSbDnR+0mS5sZsHDn8s6paX1Ub2vL1wL1VtQ64ty0DXAqsa9NW4BbohQm951JfCFwA3HAs\nUCRJo/FynFbaDGxv89uBy/vqd1TPd4DlSVYClwC7q+poVT0J7AY2vQzjkiQN6VTDoYD/leTBJFtb\n7Q1VdQigvZ7d6quAx/v6TrbaieqSpBFZeor931FVB5OcDexO8oOTtM2AWp2k3t1AL4C2ApxzzjnT\nHaskaUindORQVQfb62Hgz+ldM3iinS6ivR5uzSeBNX3dVwMHT1If9H63VtWGqtowNjZ2KkOXJJ3E\njMMhyd9L8tpj88DFwKPADuDYHUdbgHva/A7g6nbX0kbg6XbaaRdwcZIV7UL0xa0mSRqRUzmt9Abg\nz5Mc285/r6r/mWQPcHeSa4CfAFe09juBy4AJ4Dng/QBVdTTJJ4E9rd0nquroKYxLknSKZhwOVfUY\n8JYB9f8LvGtAvYBrT7CtbcC2mY5FkjS7/IW0JKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnq\nMBwkSR2GgySpw3CQJHUYDpKkDsNBktRxqg/7ecU5cPhZDhx+lrXX/4+B6/f8x3cz9trT53hUkjS/\neORwnB/8zc9HPQRJGrlFd+Qwlffd9sDA+hnLlrD/k5vmeDSSNBoeOQzp//3yxVEPQZLmjEcO0/A3\nT/8tAL2H30Ha/4SQ9JaTtNdenTBw3RnLlpBjG5KkecZwmIaN//neWdvW1n/6m3zssvNmbXuSNJvm\nTTgk2QT8V2AJ8CdV9ekRD+ll9Wfjj7N+zXKqoCiqevUC6thC02lTv97u9GVLeM9vr2TJqzwSkTQ7\n5kU4JFkCfA74HWAS2JNkR1V9f7Qje/k8+dwv+ddf+O6sbe/ffPGhWdvWVJb/xrKTrg+98DrmuKx7\nqV1+fd3xodhrk25YTvGefzdfg9se3+dTl7+Zy3575a+N69j6pUu8LKfFaV6EA3ABMFFVjwEkuRPY\nDCzYcHgle+q5X456CLPqQ3ft5UN37R31MKShrPiNZTz0ny5+2d9nvoTDKuDxvuVJ4MLjGyXZCmwF\nOOecc2b0Rj/+9Htm1G/i8LP8qurvLigf7/gvvQV89eFDPH70OaBdvD4m/bMvXcwG+Iu9P+WXL57s\n+66kxewdbzxrTt5nvoTDoJPlnb+QVXUrcCvAhg0b5vQv6BvPfs20+/zb33nttPv8lyveMu0+kjTb\n5ssJ1UlgTd/yauDgiMYiSYvefAmHPcC6JOcmOQ24Etgx4jFJ0qI1L04rVdULSa4DdtG7lXVbVe0b\n8bAkadGaF+EAUFU7gZ2jHockaf6cVpIkzSOGgySpw3CQJHUYDpKkjgz692xeCZIcAf76JE3OAn42\nR8OZz9wPL3Ff9LgfehbrfvgHVTU2VaNXbDhMJcl4VW0Y9ThGzf3wEvdFj/uhx/1wcp5WkiR1GA6S\npI6FHA63jnoA84T74SXuix73Q4/74SQW7DUHSdLMLeQjB0nSDC3IcEiyKckPk0wkuX7U45krSbYl\nOZzk0b7amUl2JznQXleMcoxzIcmaJPcl2Z9kX5IPtvqi2hdJXp3kgSTfa/vh461+bpL72364q/1L\nyAtekiVJHkry1ba8KPfDsBZcOPQ9j/pS4HzgqiTnj3ZUc+Z2YNNxteuBe6tqHXBvW17oXgA+XFXn\nARuBa9v/BxbbvngeuKiq3gKsBzYl2Qh8Brip7YcngWtGOMa59EFgf9/yYt0PQ1lw4UDf86ir6hfA\nsedRL3hV9U3g6HHlzcD2Nr8duHxOBzUCVXWoqr7b5p+h9wdhFYtsX1TPs21xWZsKuAj4Uqsv+P0A\nkGQ18B7gT9pyWIT7YToWYjgMeh71qhGNZT54Q1Udgt4fTeDsEY9nTiVZC7wVuJ9FuC/aqZS9wGFg\nN/BXwFNV9UJrslj++/gj4D8Av2rLr2dx7oehLcRwGOp51Fr4krwG+DLwoar6+ajHMwpV9WJVraf3\n6N0LgPMGNZvbUc2tJL8LHK6qB/vLA5ou6P0wXfPmYT+zyOdR/7onkqysqkNJVtL7BrngJVlGLxi+\nUFVfaeVFuS8AquqpJN+gdw1meZKl7VvzYvjv4x3AP09yGfBq4HX0jiQW236YloV45ODzqH/dDmBL\nm98C3DPCscyJdj75NmB/VX22b9Wi2hdJxpIsb/NnAO+md/3lPuC9rdmC3w9V9dGqWl1Va+n9Pfh6\nVf0LFtl+mK4F+SO49g3hj3jpedQ3jnhIcyLJF4F30vvXJp8AbgD+ArgbOAf4CXBFVR1/0XpBSfJP\ngP8NPMJL55g/Ru+6w6LZF0n+Eb0LrUvofRG8u6o+keQ36d2ocSbwEPAvq+r50Y107iR5J/Dvqup3\nF/N+GMaCDAdJ0qlZiKeVJEmnyHCQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkd/x+8ULF8\nlokZcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1891636b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_axis,Y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni=list(unique.copy())  #making a copy and converting it into list\n",
    "freq=list(frequency.copy()) #making a copy and converting it into list\n",
    "i=0\n",
    "while(True):    \n",
    "    if(i<len(freq)):      \n",
    "        if freq[i]<=100:  #deleting the unique elements with frequency less than 100\n",
    "            del freq[i]\n",
    "            del uni[i]\n",
    "            continue\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "        \n",
    "        #mind, using while loop as true, because cant use for loop, with each deletion of element, the index changes\n",
    "        #thus,i am making the check with the len of list each time while running the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form(data,x,uni,row):\n",
    "    for i in data:\n",
    "        if i not in uni:\n",
    "            continue\n",
    "        w=uni.index(i)    #finding the index value of the word in my vocabulary\n",
    "        x[row][w]+=1      #adding 1 in the column as specified\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train=np.zeros(shape=(len(X_train_files),len(uni)))  #Creating a X_train of size as training files X size of my vocabulary\n",
    "i=0\n",
    "\n",
    "for file in X_train_files:\n",
    "    \n",
    "    data=load(file)  #getting all the words of one document at a time in the list named data\n",
    "    X_train=form(data,X_train,uni,i)  \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now, forming X_test\n",
    "X_test=np.zeros(shape=(len(X_test_files),len(uni)))\n",
    "i=0\n",
    "#foor loopp use kar\n",
    "for file in X_test_files:\n",
    "    \n",
    "    data=load(file)\n",
    "    X_test=form(data,X_test,uni,i)  #in the similar way making X_test\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.70      0.78      0.74       233\n",
      "           comp.graphics       0.73      0.72      0.72       253\n",
      " comp.os.ms-windows.misc       0.73      0.80      0.76       249\n",
      "comp.sys.ibm.pc.hardware       0.78      0.85      0.82       240\n",
      "   comp.sys.mac.hardware       0.80      0.85      0.82       236\n",
      "          comp.windows.x       0.86      0.79      0.82       240\n",
      "            misc.forsale       0.74      0.80      0.77       261\n",
      "               rec.autos       0.85      0.87      0.86       269\n",
      "         rec.motorcycles       0.82      0.91      0.86       284\n",
      "      rec.sport.baseball       0.81      0.89      0.85       248\n",
      "        rec.sport.hockey       0.92      0.74      0.82       231\n",
      "               sci.crypt       0.93      0.85      0.89       233\n",
      "         sci.electronics       0.88      0.85      0.87       244\n",
      "                 sci.med       0.92      0.84      0.88       256\n",
      "               sci.space       0.85      0.83      0.84       246\n",
      "  soc.religion.christian       0.86      0.95      0.90       252\n",
      "      talk.politics.guns       0.68      0.79      0.73       249\n",
      "   talk.politics.mideast       0.85      0.69      0.76       281\n",
      "      talk.politics.misc       0.62      0.56      0.59       259\n",
      "      talk.religion.misc       0.53      0.43      0.47       236\n",
      "\n",
      "             avg / total       0.79      0.79      0.79      5000\n",
      "\n",
      "[[182   1   0   0   0   0   2   0   4   2   0   0   0   0   2   2   5   1\n",
      "    3  29]\n",
      " [  1 183  23  13   1   8   4   1   4   0   1   1   4   1   7   0   0   0\n",
      "    1   0]\n",
      " [  0  12 198   9   3  10   1   0   3   1   0   1   2   0   3   0   2   0\n",
      "    4   0]\n",
      " [  0   3   5 205  14   0   7   3   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   7  10 201   3   7   0   0   0   0   0   4   1   0   0   1   0\n",
      "    1   0]\n",
      " [  0  18  12   3   6 189   2   1   2   0   1   0   1   2   2   0   0   0\n",
      "    0   1]\n",
      " [  0   3   3  11   8   1 208  10   5   1   2   4   2   0   1   0   0   1\n",
      "    1   0]\n",
      " [  2   2   2   0   2   1   8 235   4   0   1   0   4   0   2   0   2   1\n",
      "    2   1]\n",
      " [  2   0   0   0   1   0   6   3 259   1   0   0   1   1   0   2   2   0\n",
      "    6   0]\n",
      " [  2   2   1   1   1   1   5   2   3 220   8   0   1   0   0   0   0   0\n",
      "    1   0]\n",
      " [  1   0   0   0   0   0   2   2   7  41 170   2   0   0   0   2   1   0\n",
      "    1   2]\n",
      " [  1   4   2   1   1   4   1   3   0   0   0 199   0   1   0   0   4   1\n",
      "    7   4]\n",
      " [  0   5   6   5   7   1   6   4   0   1   0   1 208   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   1   0   1   0   3   3   7   0   0   0   2 216   4   0   3   3\n",
      "    3   4]\n",
      " [  2   8   3   0   0   2   2   2   2   0   1   1   2   2 204   0   2   3\n",
      "    3   7]\n",
      " [  2   1   2   0   0   0   0   0   1   0   0   0   0   1   1 239   0   2\n",
      "    1   2]\n",
      " [  2   1   1   0   2   0   7   1   3   1   0   2   1   3   1   0 196   6\n",
      "   15   7]\n",
      " [  7   2   2   0   2   0   5   2   7   1   0   1   0   3   4   5  13 195\n",
      "   21  11]\n",
      " [  8   1   2   2   1   0   4   4   3   3   1   1   1   3   7   5  32  13\n",
      "  144  24]\n",
      " [ 47   1   0   2   1   0   2   2   3   0   0   1   0   0   3  24  26   4\n",
      "   18 102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred=clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability(Xa,word,total,uni,rows):\n",
    "    #print(\"lol\",Xa.shape[0])\n",
    "    output= np.log(Xa.shape[0]) - np.log(rows) #Xa.shape[0] holds the number of rows of a particular class value, whereas rows hold the total number of X_train rows\n",
    "    \n",
    "    w=uni.index(word)    #find the index of the word in vocabulary\n",
    "    nume=Xa[:,w].sum() + 1   #finding the sum of all the occurance of the particular word and adding 1 for laplace correction\n",
    "    deno=total + len(uni)  #total holds the sum of all the words of vocabulary of the given required class and len(uni) laplace correction\n",
    "    pro=np.log(nume) - np.log(deno)   #using log and subtracting numerator and denominator\n",
    "    output=output+pro\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct(X_train,Y_train,uni):\n",
    "    result={}        \n",
    "    class_values=set(Y_train)  #extracting all the class values in Y_train\n",
    "    for i in class_values:     #iteratng over each class value\n",
    "\n",
    "        result[i]=[]      #making a list for each class value. this list will hold the frequency of the words in the vocabulary\n",
    "        current_class_rows = (Y_train==i)   #extracting all the rows of Y_train consisting of required class_value\n",
    "\n",
    "        Xa = X_train[current_class_rows]  #extracting all the rows of Y_train consisting of required class_value\n",
    "        \n",
    "        total_sum_of_values_of_class=Xa.sum()  #the sum of all the words of vocabulary of the given required class\n",
    "        #print(total_sum_of_values_of_class)\n",
    "        for j in uni:\n",
    "            m=probability(Xa,j,total_sum_of_values_of_class,uni,X_train.shape[0])    #iterating through each word of vocabulary and sending it to probability function\n",
    "            #print(m)\n",
    "            result[i].append(m)  #finally appending it in list\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train=np.array(Y_train) #very important step as Y_train was a List, converting it to numpy array will come in handy for current_class_rows in predict\n",
    "\n",
    "dictionary=construct(X_train,Y_train,uni)  #calling construct function to make the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_dict(w,dictionary,current_class):\n",
    "    return dictionary[current_class][w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form2(data,dictionary,uni):\n",
    "    classes=dictionary.keys()   #class values in the dictionary\n",
    "    best_p=-1000\n",
    "    best_class=-1\n",
    "    first_run=True\n",
    "    tot=0\n",
    "    for current_class in classes:   #iterating over all the class values one by one to find the maximum probability\n",
    "        tot=0\n",
    "        for i in data:       # iterating over all the words one by one of a document\n",
    "            if i not in uni:\n",
    "                continue\n",
    "            w=uni.index(i)  #  finding the index of the word in vocabulary\n",
    "            tot+=check_dict(w,dictionary,current_class)  #calling check_dict() to get the required probability with respect to the training data\n",
    "        if(first_run or tot>best_p):  #finding the best class\n",
    "            best_p=tot                  #holding the best probability value\n",
    "            best_class=current_class      #holding the best class\n",
    "        first_run = False               #this is used to make the best_p and best_class hold the best class only for the very first iteration and then making it false\n",
    "    return best_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Y_pred=[]\n",
    "for file in X_test_files:\n",
    "    data=load(file)\n",
    "    Y_pred.append(form2(data,dictionary,uni))   #appending the best class in Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.80      0.73       233\n",
      "           comp.graphics       0.75      0.70      0.73       253\n",
      " comp.os.ms-windows.misc       0.74      0.80      0.77       249\n",
      "comp.sys.ibm.pc.hardware       0.77      0.85      0.81       240\n",
      "   comp.sys.mac.hardware       0.77      0.87      0.82       236\n",
      "          comp.windows.x       0.86      0.81      0.83       240\n",
      "            misc.forsale       0.74      0.79      0.77       261\n",
      "               rec.autos       0.86      0.87      0.86       269\n",
      "         rec.motorcycles       0.90      0.89      0.90       284\n",
      "      rec.sport.baseball       0.83      0.89      0.86       248\n",
      "        rec.sport.hockey       0.92      0.77      0.84       231\n",
      "               sci.crypt       0.91      0.87      0.89       233\n",
      "         sci.electronics       0.85      0.86      0.85       244\n",
      "                 sci.med       0.93      0.84      0.88       256\n",
      "               sci.space       0.83      0.85      0.84       246\n",
      "  soc.religion.christian       0.87      0.95      0.91       252\n",
      "      talk.politics.guns       0.66      0.81      0.73       249\n",
      "   talk.politics.mideast       0.89      0.61      0.72       281\n",
      "      talk.politics.misc       0.64      0.53      0.58       259\n",
      "      talk.religion.misc       0.50      0.47      0.49       236\n",
      "\n",
      "             avg / total       0.80      0.79      0.79      5000\n",
      "\n",
      "[[187   1   0   0   0   0   2   1   2   1   0   0   0   0   2   2   7   0\n",
      "    1  27]\n",
      " [  1 178  22  14   3  10   4   1   3   0   1   3   4   1   7   0   0   0\n",
      "    1   0]\n",
      " [  0  12 200   9   4  10   1   0   0   1   0   1   2   0   3   0   2   0\n",
      "    3   1]\n",
      " [  0   3   5 205  14   0   7   3   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   6  10 205   3   6   0   0   0   0   0   4   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0  13  12   3   6 195   2   1   1   0   1   1   1   1   2   0   0   0\n",
      "    0   1]\n",
      " [  0   1   3  11  10   1 207   9   2   1   2   4   6   0   2   0   0   1\n",
      "    1   0]\n",
      " [  3   1   2   2   3   1   8 234   3   0   1   0   4   0   2   0   3   0\n",
      "    2   0]\n",
      " [  2   0   1   0   1   0   6   4 253   1   0   0   3   1   0   2   3   0\n",
      "    6   1]\n",
      " [  2   2   1   1   1   1   5   2   2 221   8   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   1   4   3  35 179   2   0   0   0   2   1   0\n",
      "    1   2]\n",
      " [  1   3   2   1   1   4   1   2   0   0   1 202   1   1   1   0   2   0\n",
      "    6   4]\n",
      " [  0   5   6   6   8   1   4   3   0   1   0   1 209   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   4   0   1   2   0   3   2   5   1   0   1   2 214   5   0   4   2\n",
      "    2   5]\n",
      " [  3   8   3   0   1   2   2   0   0   0   1   1   2   2 208   0   2   1\n",
      "    2   8]\n",
      " [  2   1   2   0   0   0   0   0   0   0   0   0   0   1   1 240   0   2\n",
      "    1   2]\n",
      " [  2   1   1   0   2   0   7   0   1   1   0   2   1   3   1   0 202   4\n",
      "   13   8]\n",
      " [ 11   2   2   0   3   0   6   2   3   1   0   1   1   3   5   3  18 172\n",
      "   27  21]\n",
      " [ 11   1   2   2   1   0   4   4   1   3   1   1   1   3   8   5  35   9\n",
      "  136  31]\n",
      " [ 50   1   1   2   1   0   2   1   1   0   0   1   0   0   3  21  25   3\n",
      "   12 112]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
